{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTIqwtg05D9z7mnEnlDm54",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robert-pineau/CIND-860-Capstone/blob/main/CIND860_image_prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pylibjpeg\n",
        "!pip install pydicom\n",
        "!pip install pylibjpeg-libjpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeEo8znxxhP2",
        "outputId": "42c1ac60-dcde-4162-a6d3-45176e96af9c"
      },
      "execution_count": null,
      "outputs": []
      },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWfXfgoMxRMV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import re\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import libjpeg\n",
        "import pylibjpeg\n",
        "import pydicom as dicom\n",
        "import skimage as ski\n",
        "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
        "from pydicom.pixel_data_handlers.util import apply_voi\n",
        "from pydicom.pixel_data_handlers.util import apply_modality_lut\n",
        "from pydicom.pixel_data_handlers.util import apply_windowing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_base_dir= \"/mnt/wd/CIND860/database/train_images\"\n",
        "image_dir= \"/mnt/wd/CIND860/database/square_cc_images\"\n",
        "dataset_file = \"/mnt/wd/CIND860/train.csv\"\n",
        "used_type = \"CC\""
      ],
      "metadata": {
        "id": "CIqtuNMZjsRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Based on a sampling of 5000 images after auto-croping\n",
        "#the average aspect ratio was approximately 2.0:1\n",
        "#For a neural network, was going to reduce image to 512x1024\n",
        "#\n",
        "#However, in order to use a predefined model, and their pre-trained weights\n",
        "#need to make the images square, as more models use 224x224, or 227x227.\n",
        "#\n",
        "def lin_scale(img, new_w=1024, new_h=1024, colour='black'):\n",
        "   aspect_ratio = img.shape[0]/img.shape[1]\n",
        "\n",
        "   calc_h = int(new_w*(img.shape[0]/img.shape[1]))\n",
        "   calc_w = int(new_h*(img.shape[1]/img.shape[0]))\n",
        "\n",
        "   if colour == 'white':\n",
        "      pad_colour = [255,255,255]\n",
        "   else:\n",
        "      pad_colour = [0,0,0]\n",
        "\n",
        "\n",
        "   if calc_h > new_h:\n",
        "      #calc height is larger than desired height.\n",
        "      #therefore scale to x=calc_w, y=new_h\n",
        "      #then pad right make x == new_w\n",
        "      resize = cv2.resize(img, (calc_w,new_h))\n",
        "      pad = new_w-calc_w\n",
        "      resize2 = cv2.copyMakeBorder(resize,0,0,0,pad,cv2.BORDER_CONSTANT,None,pad_colour)\n",
        "\n",
        "   else:\n",
        "      #calc height is smaller than desired height.\n",
        "      #therefore scale to x=new_w, y=calc_h\n",
        "      #then pad top and bottom to make y == new_h\n",
        "      resize = cv2.resize(img, (new_w,calc_h))\n",
        "\n",
        "      pad = new_h-calc_h\n",
        "      #Need to split pad up so we keep image centered top to bottom as cropped.\n",
        "      #(ie pad half on bottom, half on top.\n",
        "      pad1 = int(pad/2)\n",
        "      pad2 = pad-pad1\n",
        "      resize2 = cv2.copyMakeBorder(resize,pad1,pad2,0,0,cv2.BORDER_CONSTANT,None,pad_colour)\n",
        "\n",
        "   return(resize2)\n",
        "\n",
        "\n",
        "#Need to go through all the found images, count only view type 'CC', without implant, and cancerous.\n",
        "#This number will be used to count a suitable balanced set of non cancerous images.\n",
        "def get_cancer_count(image_list,used_type):\n",
        "  cancer_count = 0\n",
        "\n",
        "  for dcm_name in image_list:\n",
        "    result = re.search(r\"\\/(\\d+)\\/(\\d+)\\.dcm\", dcm_name)\n",
        "    patient_id = int(result.group(1))\n",
        "    image_id = int(result.group(2))\n",
        "\n",
        "    my_index = np.where(df['image_id'] == image_id)[0]\n",
        "    image_type = df.at[int(my_index),'view']\n",
        "    implant = df.at[int(my_index),'implant']\n",
        "    cancer = df.at[int(my_index),'cancer']\n",
        "\n",
        "    if implant:\n",
        "      continue\n",
        "\n",
        "    if image_type != used_type:\n",
        "      continue\n",
        "\n",
        "    if cancer:\n",
        "      cancer_count += 1\n",
        "\n",
        "    return cancer_count\n",
        "\n",
        "\n",
        "\n",
        "def process_image(image_dir,image_id,dcm_name):\n",
        "  png_name = re.sub(r'\\.dcm$', '.png', dcm_name)\n",
        "  #print(f\"{dcm_name}-->{png_name}:\")\n",
        "\n",
        "  #Read dicom(mammogram/xray file in)\n",
        "  dcm = dicom.dcmread(dcm_name)\n",
        "\n",
        "  #Extract into pixels.\n",
        "  img = dcm.pixel_array.astype(np.float64)\n",
        "\n",
        "  #apply conversion to greyscale.\n",
        "  #only if the VOI LUT data is present in the dicom file.\n",
        "  if [0x0028, 0x1056] in dcm:\n",
        "    img = apply_voi_lut(img, dcm, index=0)\n",
        "\n",
        "  #Rescale colour of each pixel into 8 bits\n",
        "  img = (np.maximum(img, 0) / img.max()) * 255.0\n",
        "\n",
        "  #Convert to uint8\n",
        "  img = img.astype(np.uint8)\n",
        "\n",
        "  #Convert from single channel colour into BGR format.\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "  #Some dicom files were type \"MONOCHROME1\" and some \"MONOCHROME2\"\n",
        "  #The MONOCROME1 files are white based, whereas the MONOCHROME2 are the more customary black based.\n",
        "  #Invert colours if dicom was type \"MONOCHROME1\"\n",
        "  if dcm[0x0028, 0x0004].value == 'MONOCHROME1':\n",
        "    img = 255-img\n",
        "\n",
        "  #Calculate Aspect ratio of the original incoming file\n",
        "  aspect_ratio_in = img.shape[0]/img.shape[1]\n",
        "\n",
        "  #this returns 0 or 255 for every pixel if it is in the range between lower and upper.\n",
        "  #for this purposes, we want to identify what part of the image is non black.\n",
        "  threshold = cv2.inRange(img, lower, upper)\n",
        "\n",
        "  #this finds contours within the image after the non black areas were identified.\n",
        "  contours = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "\n",
        "  #find the main contour in the image, basically the area with the most infomation.\n",
        "  main_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "  # get a rectangle bounding the main contour.\n",
        "  x,y,w,h = cv2.boundingRect(main_contour)\n",
        "\n",
        "  #add some padding to the values. (50 pixels to top and bottom, and 150 pixels to sides.)\n",
        "  #The min and max functions prevent going beyond the image's bounds.\n",
        "  x1 = max(0,x-150)\n",
        "  y1 = max(0,y-50)\n",
        "  x2 = min(img.shape[1],x+w+150)\n",
        "  y2 = min(img.shape[0],y+h+50)\n",
        "\n",
        "  # crop the image at the bounds\n",
        "  crop = img[y1:y2, x1:x2]\n",
        "\n",
        "  if x > 100:\n",
        "    #breast image is left facing, therefore want to flip it on the horizontal axis.\n",
        "    crop = cv2.flip(crop,1)\n",
        "\n",
        "  #Use out custom resize method.\n",
        "  resize = lin_resize(crop,1024,1024,'black')\n",
        "\n",
        "  #Write as a png file.\n",
        "  cv2.imwrite(f\"{image_dir}/{image_id}.png\", resize)\n"
      ],
      "metadata": {
        "id": "uNdKsmStyzFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For the automatic cropping of the image being performed below.\n",
        "# set color bounds of white region\n",
        "lower = (10,10,10) # lower bound for each channel(RGB)\n",
        "upper = (255,255,255) # upper bound for each channel(RGB)\n",
        "\n",
        "\n",
        "#Read in the database file for details regarding each image/patient.\n",
        "df=pd.read_csv(dataset_file,sep=',')\n",
        "\n",
        "image_list = glob.glob(os.path.join(\"\", f\"{image_base_dir}/*/*.dcm\"))\n",
        "random.shuffle(image_list)\n",
        "\n",
        "cancer_count = get_cancer_count(image_list,used_type)\n",
        "\n",
        "#We are looking for a balanced dataset, so get equal number of cacncerous, and non-cancerous images.\n",
        "images_needed = cancer_count\n",
        "with_cn = 0\n",
        "without_cn = 0\n",
        "\n",
        "for dcm_name in image_list:\n",
        "  result = re.search(r\"\\/(\\d+)\\/(\\d+)\\.dcm\", dcm_name)\n",
        "  patient_id = int(result.group(1))\n",
        "  image_id = int(result.group(2))\n",
        "\n",
        "  my_index = np.where(df['image_id'] == image_id)[0]\n",
        "  image_type = df.at[int(my_index),'view']\n",
        "  implant = df.at[int(my_index),'implant']\n",
        "  cancer = df.at[int(my_index),'cancer']\n",
        "\n",
        "  #Skipping any with implants.\n",
        "  if implant:\n",
        "    continue\n",
        "\n",
        "  if image_type != used_type:\n",
        "    continue\n",
        "\n",
        "  #Keep track of how many images for each of \"With Cancer\" and \"Without Cancer\" have been\n",
        "  #converted and re-saved.\n",
        "  #Once we get to the limit, stop processing files.\n",
        "  if cancer and with_cn < images_needed:\n",
        "    with_cn += 1\n",
        "  elif not cancer and without_cn < images_needed:\n",
        "    without_cn += 1\n",
        "  else:\n",
        "    continue\n",
        "\n",
        "  #If we get this far we will use this image:\n",
        "  print(f\"Patient ID:***{patient_id}*** Image ID:***{image_id}*** Image Type:***{image_type}*** Implant: ***{implant}*** Cancer: ***{cancer}***\")\n",
        "\n",
        "  process_image(image_dir,image_id,dcm_name)\n",
        "\n",
        "print(f\"FOUND ***{with_cn+without_cn}*** images total\")\n",
        "print(f\"FOUND ***{with_cn}*** with cancer\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "mxqe5WZuy4sf",
        "outputId": "2a53c69b-9e77-4303-9a3b-658d16e869a9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
