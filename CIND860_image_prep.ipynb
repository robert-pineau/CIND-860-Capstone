{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTIqwtg05D9z7mnEnlDm54",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robert-pineau/CIND-860-Capstone/blob/main/CIND860_image_prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pylibjpeg\n",
        "!pip install pydicom\n",
        "!pip install pylibjpeg-libjpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeEo8znxxhP2",
        "outputId": "42c1ac60-dcde-4162-a6d3-45176e96af9c"
      },
      "execution_count": null,
      "outputs": [],
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWfXfgoMxRMV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import re\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import libjpeg\n",
        "import pylibjpeg\n",
        "import pydicom as dicom\n",
        "import skimage as ski\n",
        "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
        "from pydicom.pixel_data_handlers.util import apply_voi\n",
        "from pydicom.pixel_data_handlers.util import apply_modality_lut\n",
        "from pydicom.pixel_data_handlers.util import apply_windowing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_base_dir= \"/mnt/wd/CIND860/database/train_images\"\n",
        "image_dir= \"/mnt/wd/CIND860/database/square_cc_images\"\n",
        "dataset_file = \"/mnt/wd/CIND860/train.csv\"\n",
        "used_type = \"CC\""
      ],
      "metadata": {
        "id": "CIqtuNMZjsRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Based on a sampling of 5000 images after auto-croping\n",
        "#the average aspect ratio was approximately 2.0:1\n",
        "#For a neural network, was going to reduce image to 512x1024\n",
        "#\n",
        "#However, in order to use a predefined model, and their pre-trained weights\n",
        "#need to make the images square, as more models use 224x224, or 227x227.\n",
        "#\n",
        "def lin_scale(img, new_w=1024, new_h=1024, colour='black'):\n",
        "   aspect_ratio = img.shape[0]/img.shape[1]\n",
        "\n",
        "   calc_h = int(new_w*(img.shape[0]/img.shape[1]))\n",
        "   calc_w = int(new_h*(img.shape[1]/img.shape[0]))\n",
        "\n",
        "   if colour == 'white':\n",
        "      pad_colour = [255,255,255]\n",
        "   else:\n",
        "      pad_colour = [0,0,0]\n",
        "\n",
        "\n",
        "   if calc_h > new_h:\n",
        "      #calc height is larger than desired height.\n",
        "      #therefore scale to x=calc_w, y=new_h\n",
        "      #then pad right make x == new_w\n",
        "      resize = cv2.resize(img, (calc_w,new_h))\n",
        "      pad = new_w-calc_w\n",
        "      resize2 = cv2.copyMakeBorder(resize,0,0,0,pad,cv2.BORDER_CONSTANT,None,pad_colour)\n",
        "\n",
        "   else:\n",
        "      #calc height is smaller than desired height.\n",
        "      #therefore scale to x=new_w, y=calc_h\n",
        "      #then pad top and bottom to make y == new_h\n",
        "      resize = cv2.resize(img, (new_w,calc_h))\n",
        "\n",
        "      pad = new_h-calc_h\n",
        "      #Need to split pad up so we keep image centered top to bottom as cropped.\n",
        "      #(ie pad half on bottom, half on top.\n",
        "      pad1 = int(pad/2)\n",
        "      pad2 = pad-pad1\n",
        "      resize2 = cv2.copyMakeBorder(resize,pad1,pad2,0,0,cv2.BORDER_CONSTANT,None,pad_colour)\n",
        "\n",
        "   return(resize2)\n",
        "\n",
        "\n",
        "#Need to go through all the found images, count only view type 'CC', without implant, and cancerous.\n",
        "#This number will be used to count a suitable balanced set of non cancerous images.\n",
        "def get_cancer_count(image_list,used_type):\n",
        "  cancer_count = 0\n",
        "\n",
        "  for dcm_name in image_list:\n",
        "    result = re.search(r\"\\/(\\d+)\\/(\\d+)\\.dcm\", dcm_name)\n",
        "    patient_id = int(result.group(1))\n",
        "    image_id = int(result.group(2))\n",
        "\n",
        "    my_index = np.where(df['image_id'] == image_id)[0]\n",
        "    image_type = df.at[int(my_index),'view']\n",
        "    implant = df.at[int(my_index),'implant']\n",
        "    cancer = df.at[int(my_index),'cancer']\n",
        "\n",
        "    if implant:\n",
        "      continue\n",
        "\n",
        "    if image_type != used_type:\n",
        "      continue\n",
        "\n",
        "    if cancer:\n",
        "      cancer_count += 1\n",
        "\n",
        "    return cancer_count\n",
        "\n",
        "\n",
        "\n",
        "def process_image(image_dir,image_id,dcm_name):\n",
        "  png_name = re.sub(r'\\.dcm$', '.png', dcm_name)\n",
        "  #print(f\"{dcm_name}-->{png_name}:\")\n",
        "\n",
        "  #Read dicom(mammogram/xray file in)\n",
        "  dcm = dicom.dcmread(dcm_name)\n",
        "\n",
        "  #Extract into pixels.\n",
        "  img = dcm.pixel_array.astype(np.float64)\n",
        "\n",
        "  #apply conversion to greyscale.\n",
        "  #only if the VOI LUT data is present in the dicom file.\n",
        "  if [0x0028, 0x1056] in dcm:\n",
        "    img = apply_voi_lut(img, dcm, index=0)\n",
        "\n",
        "  #Rescale colour of each pixel into 8 bits\n",
        "  img = (np.maximum(img, 0) / img.max()) * 255.0\n",
        "\n",
        "  #Convert to uint8\n",
        "  img = img.astype(np.uint8)\n",
        "\n",
        "  #Convert from single channel colour into BGR format.\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "  #Some dicom files were type \"MONOCHROME1\" and some \"MONOCHROME2\"\n",
        "  #The MONOCROME1 files are white based, whereas the MONOCHROME2 are the more customary black based.\n",
        "  #Invert colours if dicom was type \"MONOCHROME1\"\n",
        "  if dcm[0x0028, 0x0004].value == 'MONOCHROME1':\n",
        "    img = 255-img\n",
        "\n",
        "  #Calculate Aspect ratio of the original incoming file\n",
        "  aspect_ratio_in = img.shape[0]/img.shape[1]\n",
        "\n",
        "  #this returns 0 or 255 for every pixel if it is in the range between lower and upper.\n",
        "  #for this purposes, we want to identify what part of the image is non black.\n",
        "  threshold = cv2.inRange(img, lower, upper)\n",
        "\n",
        "  #this finds contours within the image after the non black areas were identified.\n",
        "  contours = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "\n",
        "  #find the main contour in the image, basically the area with the most infomation.\n",
        "  main_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "  # get a rectangle bounding the main contour.\n",
        "  x,y,w,h = cv2.boundingRect(main_contour)\n",
        "\n",
        "  #add some padding to the values. (50 pixels to top and bottom, and 150 pixels to sides.)\n",
        "  #The min and max functions prevent going beyond the image's bounds.\n",
        "  x1 = max(0,x-150)\n",
        "  y1 = max(0,y-50)\n",
        "  x2 = min(img.shape[1],x+w+150)\n",
        "  y2 = min(img.shape[0],y+h+50)\n",
        "\n",
        "  # crop the image at the bounds\n",
        "  crop = img[y1:y2, x1:x2]\n",
        "\n",
        "  if x > 100:\n",
        "    #breast image is left facing, therefore want to flip it on the horizontal axis.\n",
        "    crop = cv2.flip(crop,1)\n",
        "\n",
        "  #Use out custom resize method.\n",
        "  resize = lin_resize(crop,1024,1024,'black')\n",
        "\n",
        "  #Write as a png file.\n",
        "  cv2.imwrite(f\"{image_dir}/{image_id}.png\", resize)\n"
      ],
      "metadata": {
        "id": "uNdKsmStyzFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For the automatic cropping of the image being performed below.\n",
        "# set color bounds of white region\n",
        "lower = (10,10,10) # lower bound for each channel(RGB)\n",
        "upper = (255,255,255) # upper bound for each channel(RGB)\n",
        "\n",
        "\n",
        "#Read in the database file for details regarding each image/patient.\n",
        "df=pd.read_csv(dataset_file,sep=',')\n",
        "\n",
        "image_list = glob.glob(os.path.join(\"\", f\"{image_base_dir}/*/*.dcm\"))\n",
        "random.shuffle(image_list)\n",
        "\n",
        "cancer_count = get_cancer_count(image_list,used_type)\n",
        "\n",
        "#We are looking for a balanced dataset, so get equal number of cacncerous, and non-cancerous images.\n",
        "images_needed = cancer_count\n",
        "with_cn = 0\n",
        "without_cn = 0\n",
        "\n",
        "for dcm_name in image_list:\n",
        "  result = re.search(r\"\\/(\\d+)\\/(\\d+)\\.dcm\", dcm_name)\n",
        "  patient_id = int(result.group(1))\n",
        "  image_id = int(result.group(2))\n",
        "\n",
        "  my_index = np.where(df['image_id'] == image_id)[0]\n",
        "  image_type = df.at[int(my_index),'view']\n",
        "  implant = df.at[int(my_index),'implant']\n",
        "  cancer = df.at[int(my_index),'cancer']\n",
        "\n",
        "  #Skipping any with implants.\n",
        "  if implant:\n",
        "    continue\n",
        "\n",
        "  if image_type != used_type:\n",
        "    continue\n",
        "\n",
        "  #Keep track of how many images for each of \"With Cancer\" and \"Without Cancer\" have been\n",
        "  #converted and re-saved.\n",
        "  #Once we get to the limit, stop processing files.\n",
        "  if cancer and with_cn < images_needed:\n",
        "    with_cn += 1\n",
        "  elif not cancer and without_cn < images_needed:\n",
        "    without_cn += 1\n",
        "  else:\n",
        "    continue\n",
        "\n",
        "  #If we get this far we will use this image:\n",
        "  print(f\"Patient ID:***{patient_id}*** Image ID:***{image_id}*** Image Type:***{image_type}*** Implant: ***{implant}*** Cancer: ***{cancer}***\")\n",
        "\n",
        "  process_image(image_dir,image_id,dcm_name)\n",
        "\n",
        "print(f\"FOUND ***{with_cn+without_cn}*** images total\")\n",
        "print(f\"FOUND ***{with_cn}*** with cancer\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "mxqe5WZuy4sf",
        "outputId": "2a53c69b-9e77-4303-9a3b-658d16e869a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ca4694b73593>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Read in the database file for details regarding each image/patient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdataset_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
          ]
        }
      ]
    }
  ]
}
